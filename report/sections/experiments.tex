\subsection{Experiment 1}
The first experiment performed compares the different architectures using the 
\emph{Mean Squared Error (MSE)} loss function.
The baseline model is able to reach the goal, but with little precision and 
often colliding with the object, as shown in Figure~\ref{fig:baseline}.

\begin{figure}[htbp]
	\centerline{\includegraphics[width=\columnwidth]{experiments/1/demo-trajectories-baseline}}
	\caption{Trajectories of the controller learned from the baseline network.}
	\label{fig:baseline}
\end{figure}

\begin{figure}[htbp]
	\centerline{\includegraphics[width=\columnwidth]{experiments/1/regression-validation-baseline}}
	\caption{$R^2$ regressor on the validation set of the baseline network.}
	\label{fig:regression-baseline}
\end{figure}

Adding either max pooling or dropout alone does not solve the problem, but 
combining them results in a visible improvement: the robot reaches the goal 
position more precisely even if oscillating a bit.

\begin{figure}[htbp]
	\centerline{\includegraphics[width=\columnwidth]{experiments/1/demo-trajectories-maxpool+dropout}}
	\caption{Trajectories of the controller learned from the max pooling + 
	dropout network.}
	\label{fig:maxpool+dropout}
\end{figure}

\begin{figure}[htbp]
	\centerline{\includegraphics[width=\columnwidth]{experiments/1/regression-validation-maxpool+dropout}}
	\caption{$R^2$ regressor on the validation set of the max pooling + dropout 
	network.}
	\label{fig:regression-maxpool+dropout}
\end{figure}

The regression coefficient of the angular velocity, displayed in 
Figure~\ref{fig:regression-maxpool+dropout}, increases from $0.54$ to $0.64$ 
compared to Figure~\ref{fig:regression-baseline}, confirming the improvement of 
the second model. As shown in Figure~\ref{fig:loss}, it shows also a lower 
validation loss (in red) and does not overfit toward the end of training, like 
the baseline model (in orange).

\begin{figure}[htbp]
\centerline{\includegraphics[width=.8\columnwidth]{experiments/1/loss}}
	\caption{Comparison of the losses among train and validation sets.}
	\label{fig:loss}
\end{figure}

Finally, the end positions are more tightly clustered over the goal.
Both heat maps in Figure~\ref{fig:heatmaps} show a tendency to rotate around 
the object, which are caused by its symmetry. We will explore this issue in 
Section~\ref{experiment3}.

\begin{figure}[htbp]
	\centerline{\includegraphics[width=\columnwidth]{experiments/1/heatmaps}}
	\caption{Positions heat maps.}
	\label{fig:heatmaps}
\end{figure}

\begin{figure}[htbp]
	\centerline{\includegraphics[width=\columnwidth]{experiments/1/final-positions}}
	\caption{Final positions.}
	\label{fig:final-positions}
\end{figure}

Even though the overall behaviour of this model is good, the main drawback is a 
slight systematic error in the final orientation that can be seen in 
Figure~\ref{fig:distance-from-goal-learned}.

\begin{figure}[htbp]
	\centerline{\includegraphics[width=\columnwidth]{experiments/1/distances-from-goal}}
	\caption{Distance from goal over time.}
	\label{fig:distance-from-goal-learned}
\end{figure}

\subsection{Experiment 2}
The second experiment evaluates the performance of the same max pooling + 
dropout model, but trained with a different loss function, \emph{Smooth 
L1} \cite{smoothl1}, which is less sensitive to outliers than \emph{MSE} and 
has been shown to prevent exploding gradients in some cases. It is computed as

\begin{equation}
\text{L}(x, y) = \frac{1}{n}\sum_{i}z_i
\label{smoothl1}
\end{equation}

where $z_i$ is given by

\begin{equation}
z_i = 
\begin{cases}
0.5 (x_i-y_i)^2, &\text{ if } |x_i-y_i|<1 \\
|x_i-y_i| - 0.5, &\text{ otherwise}
\end{cases}
\end{equation}

 
Although it results in less precise final positions, it solves the oscillation 
issue, as shown in Figure~\ref{fig:demo-trajectories}.

\begin{figure}[htbp]
	\centerline{\includegraphics[width=\columnwidth]{experiments/2/demo-trajectories}}
	\caption{Trajectories.}
	\label{fig:demo-trajectories}
\end{figure}

The regression coefficient of the angular velocity, shown in 
Figure~\ref{fig:regression-validation}, decreases from $0.64$ to $0.58$, 
confirming the superiority of the previous model.

\begin{figure}[htbp]
	\centerline{\includegraphics[width=\columnwidth]{experiments/2/regression-validation}}
	\caption{$R^2$ regressor on the validation set.}
	\label{fig:regression-validation}
\end{figure}

\subsection{Experiment 3}
\label{experiment3}

The monochromatic goal object shown so far has symmetries that make the 
trajectory to follow ambiguous, causing the robots converge to the goal in 
sub-optimal paths. One such path is visualised in 
Figure~\ref{fig:demo-circle-trajectories}, in other cases we saw the learned 
controller always moving counter-clockwise or alternating depending on the 
initial pose. 

In either case, the controller learns a good behaviour for the available data, 
ultimately reaching the goal pose, albeit following a different path. This is 
particularly interesting, considered that we only train the network to imitate 
trajectories, with no indication of the goal.

The symmetries are addressed in this final experiment, by using a polychromatic 
goal object that has a different colour for each of its faces. This removes any 
localisation ambiguity in the sensor readings.

\begin{figure}[htbp]
	\centerline{\includegraphics[width=\columnwidth]{experiments/3/monochromatic-polychromatic}}
	\caption{Comparison of the trajectories of the monochromatic and 
	polychromatic goal object.}
	\label{fig:demo-circle-trajectories}
\end{figure}

The same network architecture and loss function of the first experiment are 
used to train the the model with a polychromatic object, and result in a 
significant improvement both in regression coefficient of the angular 
velocities, shown in Figure~\ref{fig:regression-3}, and in training and 
validation losses (in green and red), in Figure~\ref{fig:loss-3}.

\begin{figure}[htbp]
	\centerline{\includegraphics[width=\columnwidth]{experiments/3/regression-validation}}
	\caption{$R^2$ regressor on the validation set.}
	\label{fig:regression-3}
\end{figure}

\begin{figure}[htbp]
	\centerline{\includegraphics[width=.8\columnwidth]{experiments/3/loss}}
	\caption{Comparison of the losses among train and validation sets.}
	\label{fig:loss-3}
\end{figure}

Finally, Figure~\ref{fig:heatmap-final-positions} shows how the end positions 
are more tightly clustered over the goal than before. Moreover, the model is 
able to follow the optimal trajectories without rotating around the object.
Also in terms of convergence, the robot reaches the goal more precisely, as 
shown in Figure~\ref{fig:distance-from-goal-learned3}, and sometimes even 
faster than the omniscient controller.

\begin{figure}[htbp]
	\centerline{\includegraphics[width=\columnwidth]{experiments/3/heatmap-final-positions}}
	\caption{Positions heatmap and final positions.}
	\label{fig:heatmap-final-positions}
\end{figure}

\begin{figure}[htbp]
	\centerline{\includegraphics[width=\columnwidth]{experiments/3/distances-from-goal}}
	\caption{Distance from goal over time.}
	\label{fig:distance-from-goal-learned3}
\end{figure}