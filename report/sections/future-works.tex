\section{Future works}
In task 2, it appears that the performance of the neural network is quite good 
at moving in the general direction of the goal, less so at arriving with the 
correct orientation or stopping at the right time.

The first issue should be mitigated by a bigger architecture and more training 
data, since at the moment we are using only 2000 runs as before, which might 
not be enough given the higher complexity of the task.

The reason for the second problem is that the omniscient controller never 
overshoots the goal, so the network does not see this situation in training.
In Task 1, we solved the same issue with a special case: we had the omniscient 
controller move in reverse when it spawns inside the arms of the object. A 
similar solution could be applied here, extending this trick to arbitrary goal 
poses.

As a future work, we could try to see what happens to the current model when 
slightly changing the shape of the object. Moreover, we could also generalised 
the network by creating multiple polychromatic object with the faces coloured 
randomly. 

Another slightly more complex task could include adding obstacles that the 
robot should avoid, for example by orbiting around them.

In another spin-off, we can consider to add a second marXbot and learn to 
control the two robots with respect to each other (distributed control).
