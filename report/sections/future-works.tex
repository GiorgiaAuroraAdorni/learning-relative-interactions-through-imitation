\section{Future works/Problems/Solutions}
In task 2, it appears that the performance of the neural network is quite good 
at moving in the general direction of the goal, less so at arriving with the 
correct orientation or stopping at the right time.

The first issue should be mitigated by a bigger architecture and more training 
data, since at the moment we are using only 2000 runs as before, which might 
not be enough given the higher complexity of the task.

The reason for the second problem is that the omniscient controller never 
overshoots the goal, so the network does not see this situation in training.
In Task 1, we solved the same issue with a special case: we had the omniscient 
controller move in reverse when it spawns inside the arms of the object. A 
similar solution could be applied here, extending this trick to arbitrary goal 
poses.

